{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bda80762-5dc9-48e1-8680-5210836ac56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wget\n",
    "#!pip install sqlalchemy\n",
    "\n",
    "from sqlalchemy import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkFiles\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import wget\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c713746a-9536-4694-a198-cb79599dc478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n",
      "end! [None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# Récupération de tous les DATASETS selectionnés en ligne\n",
    "\n",
    "choosed_stations = [\"07002099999\", \"93546099999\", \"71043599999\", \"80372099999\", \"43376099999\"]\n",
    "choosed_years = [1980, 1995, 2002, 2010] # et supérieur à 2010\n",
    "\n",
    "def get_choosed_years():\n",
    "    selected_years = choosed_years\n",
    "    currentYear = datetime.datetime.now().year\n",
    "    [selected_years.append(x) for x in range(choosed_years[-1] + 1, currentYear + 1)] \n",
    "    return selected_years\n",
    "\n",
    "def is_choosed_stations(filename):\n",
    "    file = filename.split('.')[0]\n",
    "    return file in choosed_stations\n",
    "    \n",
    "def downloadFiles(file):\n",
    "    fullLocalPath = \"data/\" + str(year) + \"/\" + str(year) + \"_\" + file\n",
    "    if not os.path.exists(fullLocalPath):\n",
    "        wget.download(url + \"/\" + file, fullLocalPath)\n",
    "        \n",
    "def printEndPool(test):\n",
    "    print('end!', test)\n",
    "\n",
    "# Définir le paramétrage du parallèlisme\n",
    "chunk_size = 2\n",
    "nb_process = 10\n",
    "\n",
    "# Parcourir les années\n",
    "for year in get_choosed_years():\n",
    "    # Ajouter le dossier\n",
    "    subDir = \"data/\" + str(year)\n",
    "    if not os.path.exists(subDir):\n",
    "        os.mkdir(subDir)\n",
    "    \n",
    "    # Parcourir les noms de fichiers\n",
    "    url = \"https://www.ncei.noaa.gov/data/global-hourly/access/\" + str(year)\n",
    "    txt = requests.get(url).text\n",
    "    files = list(re.findall(\" *(\\d{11}.csv)\", txt))\n",
    "    all_files = []\n",
    "    [all_files.append(x) for x in files if (x not in all_files) and is_choosed_stations(x)]\n",
    "\n",
    "    # Execute la fonction [downloadFiles] en parallèle avec l'argument [all_files]\n",
    "    # et divisé en plusiseurs groupe de longueur [chunk_size]\n",
    "    pool = Pool()\n",
    "    pool.map_async(downloadFiles, all_files, chunk_size, printEndPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d5d330-a9e2-45bd-844c-9db8cf76357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les datasets en local\n",
    "path = \"./data/*/*.csv\"\n",
    "df = spark.read.format('csv').options(header=True, inferSchema=True).load(path)\n",
    "\n",
    "# Toutes les colonnes du dataframe\n",
    "# ['STATION', 'DATE', 'SOURCE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', \\\n",
    "# 'NAME', 'REPORT_TYPE', 'CALL_SIGN', 'QUALITY_CONTROL', 'WND', 'CIG', \\\n",
    "# 'VIS', 'TMP', 'DEW', 'SLP', 'AA1', 'AA2', 'AY1', 'AY2', 'GA1', 'GA2', \\\n",
    "# 'GA3', 'GE1', 'GF1', 'IA1', 'KA1', 'KA2', 'MA1', 'MD1', 'MW1', 'OC1', \\\n",
    "# 'OD1', 'UA1', 'REM', 'EQD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f598863-d832-498b-a905-2e5ad277619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les colonnes pour mieux filtrer\n",
    "udf_get_year = udf(lambda date: parser.parse(date).year)\n",
    "udf_get_degree = udf(lambda tmp: float(int(tmp)/10))\n",
    "\n",
    "df = df.withColumn('TMP_DEGREE', F.split(df['TMP'], ',').getItem(0)).withColumn('TMP_QUALITY', F.split(df['TMP'], ',').getItem(1)) \n",
    "df = df.withColumn('TMP_DEGREE', udf_get_degree(col('TMP_DEGREE')))\n",
    "df = df.withColumn('TMP_DEGREE', col('TMP_DEGREE').cast(FloatType()))\n",
    "    \n",
    "df = df.withColumn('WND_SPEED', F.split(df['WND'], ',').getItem(3)).withColumn('WND_SPEED_QUALITY', F.split(df['WND'], ',').getItem(4)) \n",
    "df = df.withColumn('WND_ANGLE', F.split(df['WND'], ',').getItem(0)).withColumn('WND_ANGLE_QUALITY', F.split(df['WND'], ',').getItem(1)).withColumn('WND_TYPE', F.split(df['WND'], ',').getItem(2))  \n",
    "df = df.withColumn('CIG_HEIGHT', F.split(df['CIG'], ',').getItem(0)).withColumn('CIG_QUALITY', F.split(df['CIG'], ',').getItem(1))\n",
    "df = df.withColumn('CIG_METHOD', F.split(df['CIG'], ',').getItem(2)).withColumn('CIG_CAVOK', F.split(df['CIG'], ',').getItem(3))    \n",
    "df = df.withColumn('VIS_DISTANCE', F.split(df['VIS'], ',').getItem(0)).withColumn('VIS_DISTANCE_QUALITY', F.split(df['VIS'], ',').getItem(1))    \n",
    "df = df.withColumn('VIS_VARIABILITY', F.split(df['VIS'], ',').getItem(2)).withColumn('VIS_VARIABILITY_QUALITY', F.split(df['VIS'], ',').getItem(3))    \n",
    "df = df.withColumn('SLP_AIR_PRESSURE', F.split(df['SLP'], ',').getItem(0)).withColumn('SLP_AIR_PRESSURE_QUALITY', F.split(df['SLP'], ',').getItem(1))\n",
    "df = df.withColumn('YEAR', udf_get_year(col('DATE')))\n",
    "\n",
    "#df.select(\"YEAR\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76539f99-a5f5-4b3b-a4c9-24cecbcd8259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrer par le code qualité\n",
    "quality = [0, 1, 4, 5, 9]\n",
    "df_quality = df.where(df.TMP_QUALITY.isin(quality)).where(df.WND_SPEED_QUALITY.isin(quality)).where(df.WND_ANGLE_QUALITY.isin(quality))\\\n",
    "            .where(df.CIG_QUALITY.isin(quality)).where(df.VIS_DISTANCE_QUALITY.isin(quality)).where(df.VIS_VARIABILITY_QUALITY.isin(quality))\\\n",
    "            .where(df.SLP_AIR_PRESSURE_QUALITY.isin(quality))\n",
    "\n",
    "# Retirer les données manquantes (TEMPERATURE)\n",
    "missing_tmp = 999.9\n",
    "#df_quality_tmp = df_quality.filter(df_quality.TMP_DEGREE != missing_tmp)\n",
    "df_quality.createOrReplaceTempView('df_quality_view')\n",
    "df_quality_tmp = spark.sql(\"SELECT * FROM df_quality_view WHERE FLOAT(TMP_DEGREE) != FLOAT(\" + str(missing_tmp) + \")\")\n",
    "\n",
    "\n",
    "# Retirer les données manquantes (VENT)\n",
    "missing_wind_angle = 999\n",
    "missing_wind_speed = 9999\n",
    "df_quality_wind = df_quality.where(df_quality.WND_ANGLE != missing_wind_angle) \\\n",
    "                .where(df_quality.WND_SPEED != missing_wind_speed)\n",
    "\n",
    "# Retirer les données manquantes (CIEL)\n",
    "missing_cig_height = 99999\n",
    "missing_cig_method = 9\n",
    "df_quality_sky = df_quality.where(df_quality.CIG_HEIGHT != missing_cig_height) \\\n",
    "                .where(df_quality.CIG_METHOD != missing_cig_method)\n",
    "\n",
    "# Retirer les données manquantes (VISIBILITE)\n",
    "missing_vis_distance = 999999\n",
    "missing_vis_variability = 9\n",
    "df_quality_vis = df_quality.where(df_quality.VIS_DISTANCE != missing_vis_distance) \\\n",
    "                .where(df_quality.VIS_VARIABILITY != missing_vis_variability)\n",
    "\n",
    "#df_quality.groupby('YEAR').count().orderBy(\"YEAR\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54874bfa-24e3-45f0-a625-25d5edc0fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_database_format(df, col_name):\n",
    "    return df.groupBy(col('YEAR'), col('STATION')) \\\n",
    "            .agg(F.mean(col_name).alias('mean'), \\\n",
    "                 F.stddev(col_name).alias('std'), \\\n",
    "                 F.min(col_name).alias('min'), \\\n",
    "                 F.expr('percentile(' + col_name + ', array(0.25))')[0].alias('%25'), \\\n",
    "                 F.expr('percentile(' + col_name + ', array(0.5))')[0].alias('%50'), \\\n",
    "                 F.expr('percentile(' + col_name + ', array(0.75))')[0].alias('%75'), \\\n",
    "                 F.max(col_name).alias('max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1a1b906-eb78-4664-9169-394e1c62ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_database = {\n",
    "    # Données pour la température\n",
    "    'TEMP_CALCUL': to_database_format(df_quality_tmp, 'TMP_DEGREE').toPandas(),\n",
    "    \n",
    "    # Données pour les stations\n",
    "    'STATION': df.select(['STATION', 'LATITUDE', 'LONGITUDE', 'NAME']).distinct().toPandas()\n",
    "}\n",
    "\n",
    "#df_quality_wind.describe(['WND_SPEED']).show()\n",
    "#df_quality_sky.describe(['CIG_HEIGHT']).show()\n",
    "#df_quality_vis.describe(['VIS_DISTANCE']).show()\n",
    "#df_quality_tmp.select(['STATION','TMP_DEGREE']).distinct().orderBy(col('TMP_DEGREE').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13dd141c-fd9f-4b90-b3c8-a5bc4dc9778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion en base de données\n",
    "engine = create_engine(\"mysql://ateam:ateam@mysql:3306/ateam\")\n",
    "\n",
    "for table_name, df in to_database.items():\n",
    "    df.to_sql(table_name, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4afa917-a94f-4a2f-a6cb-ed16dbf6eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion en base de données distante\n",
    "engine = create_engine(\"mysql://266906_spark:ateamateam1234@mysql-sarahipssi.alwaysdata.net/sarahipssi_ateam\")\n",
    "\n",
    "for table_name, df in to_database.items():\n",
    "    df.to_sql(table_name, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "929707f5-6124-4267-8edd-9b7455d3e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name, df in to_database.items():\n",
    "    df.to_csv(table_name+\".csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f05586-f6ad-4ec9-85f5-5c5a2d183b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2814a18-e973-461a-a80f-dfa6fdec74a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b912c-0ce8-4bad-929d-77f668942742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
